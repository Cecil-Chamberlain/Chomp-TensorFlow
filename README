To train the network:

python3 main.py --mode train

To run the network:

python3 main.py --mode run


Command line arguments include:

--flag			description (default value)

--mode			'train' or 'run' the network (run)
--data_dir		directory dataset is stored, must include 'melody' and 'chords' folders (dataset)
--save_dir		directory where model checkpoints are saved during training (save)
--num_units		number of units in each layer of the model (512)
--num_layers		number of layers in the model (1)
--batch_size		number of simultaneous batches to train on (1)
--seq_length		sequence length of each batch (64)
--num_epochs		number of times through the data set the model will train for (10)
--grad_clip		float value to clip gradients at (1.0)
--learning_rate		float value to set the AdamOptimizer learning rate at (0.001)
--output_keep_prob	float output dropout value (0.8)
--input_keep_prob	float input dropout value (0.8)


Ensure that melody data is in the form:

32 32 32 32 35 35 35 35 38 38 38 38 39 39 39 39

(4 midi note values per beat (16th notes))


Ensure that chord data is in the following form:

Am7 Am7 D7 D7

(4 chords per bar (1/4 notes) from the chords listed in the dataset/out_vocab.txt chords document)

Ensure the same number of beats and bars (line numbers) appear in each file.

You may add new chords to the out_vocab.txt file but deletion of saved vocab.pkl and data.npy files and data preprocessing must be carried out before re-training can occur.
